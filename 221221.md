머신러닝, 딥러닝 분석 시 유용하게 쓰일 시각화 기술에 대해 학습

# matplotlib

- figure 안에 여러 개의 axes를 넣는 방식
- 반복문 기술(flatten, reshape(-1), zip 사용법) 익히기

# seaborn

하나의 figure 안에 여러 axes 넣는 건 다른 방법으로 해야 됨

axes level / figure level 방식의 차이 잘 알기!

figure level은 matplotlib과 같은 API 아니기 때문에 figsize로 사이즈 바뀌지 않음
-> height=5, aspect=2 : 높이를 5로 설정, 너비는 높이의 2배인 10으로 설정

대쉬보드나 보고서 만들 때 plotly, bokeh 이런거 쓰면 유용함

PDF 보고 복습하자~
데이터를 딱 받았을 때, plot 쭉 그려서 데이터 훑어보는 연습

이제부터 머신러닝!

머신러닝 알고리즘 요즘은 XGboost, lightGBM 얘네가 성능 가장 좋음

scikit-learn 라이브러리 -> 업계 표준
얘를 잘 다루면 머신러닝 잘한다는 소리 들음(연구자 말고 개발자 얘기)

우리는 옛날 알고리즘부터 이론적으로 배울 것

전문가 시스템 : 사람이 가진 모든 지식을 pc에 잘 집어넣어서, 사람처럼 대답해주는 것(데이터베이스 같은)
머신러닝 : 딥러닝 제외
딥러닝 :

# 머신러닝은 함수 근사임

- learn from data
- function approximation
데이터로부터 정보를 얻어
입력과 출력 사이의 그 시스템(함수)를 근사하는 것

# 머신러닝 사용할 수 있는 경우

- 데이터를 구할 수 있을 때
- 데이터에 규칙이 있다고 판단될 때
- 기존의 명시적인 프로그래밍 방법으로 해결 안되는 복잡한 문제일 때

전통적인 방법(머신러닝)은 수학적 이론 베이스 있어, 설명이 됨
딥러닝은 결과는 좋은데, 설명이 안 됨(내부가 안 보임 그래서 블랙박스라고..)
(설명 가능한 인공지능 분야 발전 중..)

- 정형 데이터 : 표 형식(데이터베이스, 스프레드시트, csv) (엑셀, pandas로 다루는..)
- 반정형 데이터 : XML, HTML
- 비정형 데이터 : 이미지, 동영상, 음성, 텍스트 (요즘 시대에 가장 많은..)

정형 데이터 -> 웬만하면 머신러닝 사용이 나음
비정형 데이터 -> 딥러닝이 더 잘 맞음, 대신 데이터 많아야 함

- 정형 데이터
특성(피쳐, 변수)
관측치(샘플, 인스턴스)
타겟(레이블, 클래스) -> 최종적으로 얻고자 하는 값

수치형 데이터 - 이산형 / 연속형
범주형 데이터 - 명목형 / 순서형

# 모델의 최종 결과가 수치형 데이터이다? -> 회귀 알고리즘 사용

ex) 중고차 가격 예측

# 모델의 최종 결과가 범주형 데이터이다? -> 카테고리를 나누는 분류 알고리즘 사용

- 2개 중 하나 분류 -> 이진 분류
ex) 남/여 분류
- 3개 이상 분류 -> 다중 분류
ex) A/B/C/ 분류

즉, 최종 결과 == '타겟'의 데이터형을 파악하고 모델을 선택해야 함

# 지도 학습

훈련 데이터에 타겟(레이블)이라는 원하는 답이 포함되어 있는 경우
비지도 학습보다 결과가 좋음
대신 데이터 구하기가 어려움..
분류 vs 회귀

- 분류 : 최종 결과가 범주형 데이터
- 회귀 : 최종 결과가 수치형 데이터
- 분류 : 두 데이터를 가장 잘 나눌 수 있는 직선 f(x)을 찾는 문제
- 회귀 : 두 데이터의 관계를 가장 잘 나타내는 직선 f(x)을 찾는 문제
f(x) => 모델

# 좋은 학습

일반화가 잘 된 모델이여야 함
현재의 데이터(train data)를 잘 예측하고,
새로운 데이터(unobserved data)가 들어왔을 때도 잘 예측해야됨

- 과소적합 :
학습이 안 된 상태
데이터 양을 늘리거나, 모델을 간단하게 만들어 해결
- 과대적합 :
일반화가 안 된 상태
훈련 데이터에만 적합
인공지능, 머신러닝의 최대 적

# 모델의 성능 평가

데이터 나누기 : Train set / Test set
Train set으로 모델 만들고, Test set으로 모델 실험

Train set의 일부를 Validation set으로 하고 모델 실험 반복
Validation set으로 계속 학습시키면 또 여기에 적합될 수도..

- > 교차검증 해보자
모델을 각 서브 셋의 조합으로 훈련시키고 검증함
ex) Train set을 5개로 나눈다고 가정
1, 2, 3, 4로 학습, 5로 테스트
1, 2, 3, 5로 학습, 4로 테스트
1, 2, 4, 5로 학습, 3으로 테스트 ...

교차검증 방법도 다양함

# 레이블 인코딩

학습은 무조건 숫자 데이터로 바꿔서 집어넣어야함
이미지, 문자열 뭐든 간에..

# 원-핫 인코딩

순위가 없는 다중 레이블을 0/1로만 인코딩

# 특성 스케일링

정규화
피쳐들의 값 범위가 다르면 동작이 잘 안되는 경우가 많음
스케일링 방법도 다양함(MinMax, Standard 등)

- MinMax Scaling
(값 - 최소값) / (최대값 - 최소값)
0~1 사이 값으로 나옴
이미지 다룰 때 많이 쓰임
rgb 픽셀 하나 당 0~255 => 0~1로 변환
이상치에 영향을 크게 받음 -> 데이터에 이상치 있을 것 같으면 쓰지 말자
ex) 이미지의 경우, 각 픽셀은 255로 구성되어 있기 때문에 이상치가 있기 어려움 -> MinMax 사|용
- Standard Scaling
값을 표준화 시킴
모든 피쳐를 평균 0, 표준편차 1을 따르게 변경
이상치에 영향을 덜 받음

---

# 데이터 정제

- 이상치 처리
- 결측치 처리

# 성능 평가

---

<분류>
정확도가 얼마냐? -> 일단 이게 기본
민감도 vs 정밀도 -> tradeoff 뭐를 더 높일지 고민

- 혼동 행렬(Confusion Matrix)
TP : 양성으로 예측, 정답도 양성
FP : 양성으로 예측, 정답은 음성
TN : 음성으로 예측, 정답도 음성
FN : 음성으로 예측, 정답은 양성
- 정확도
(TP + TN) / (TP + FP + TN + FN)
- 민감도(재현율)
TP / (TP + FN)
- 정밀도
TP / (TP + FP)
의료 인공지능이 암이라고 예측했을 때, 실제로 암일 확률
높을수록 좋겠지
- F1 점수
F1 score = 2 * 민감도 * 정밀도 / (민감도 + 정밀도)
1에 가까울수록 좋음
- Threshold와 정확도
로지스틱 회귀는 모델이 각 클래스에 속할 확률값을 출력함
출력된 확률값에서 threshold값을 비교하여 결정함

ex) 로지스틱 회귀 모델의 결과 -> 고양이 : 0.3 / 강아지 : 0.7
threshold = 0.4로 잡으면, 0.4보다 작으면 0, 크면 1로 결정

- ROC
Threshold 값을 바꿔가며, True Positive Ratio와, False Positive Ratio를 그래프로 나타낸 것
ROC 커브 아래 면적(Area under the ROC)이 1에 가까울수록 좋음

---

<회귀>
오차 = 실제값과 예측값의 차이
오차가 최소가 되도록 모델을 최적화 하는 것

- MAE = |y - y^|
오차에 절댓값 씌운 것
- MSE = (y - y^)**2 / Y평균
평균제곱오차 : 오차의 제곱을 평균으로 나눈 것
- RMSE = MSE에 루트 씌운 값
ex) MSE로 cm^2이 된 단위를 루트 씌워서 cm로 되돌린다거나..

최종적으로 원하는게 뭔지, 평가 지표가 뭔지 잘 보고 학습해야 함

- 결정계수 R square
설명변수가 반응변수를 어느 정도 설명하고 있는지 나타내는 지표
1에 가까울수록 좋음

SST : y의 평균 주위의 변동
SSR : 모델에 의해 설명되는 y의 변동
SSE : 모델에 의해 설명되지 않는 y의 변동
SST = SSR + SSE

R^2 = SSR/SST = 1-SSE/SST
